import { Cell } from "@/types/notebook";

export async function exportNotebook(pyodide: any, cells: Cell[]) {
  try {
    // Convert cells to a format that Python can understand
    const cellsData = cells.map(cell => ({
      id: cell.id,
      code: cell.code,
      parentId: cell.parentId === null ? "None" : cell.parentId // Convert null to "None" string
    }));

    // Run the export code directly
    const pythonScript = await pyodide.runPythonAsync(`
import json
from typing import Dict, List, Optional, Set
import textwrap
import sys
import re

class Cell:
    def __init__(self, id: str, code: str, parent_id: Optional[str] = None):
        self.id = id
        self.code = code
        self.parent_id = None if parent_id == "None" else parent_id  # Convert "None" string back to None

def extract_imports(code: str) -> Set[str]:
    """Extract package names from import statements."""
    imports = set()
    
    # Match 'import package' and 'from package import ...'
    import_patterns = [
        r'^import\s+(\w+)',  # import numpy
        r'^from\s+(\w+)\s+import',  # from numpy import array
        r'^import\s+(\w+)\s+as',  # import numpy as np
    ]
    
    for line in code.split('\\n'):
        line = line.strip()
        for pattern in import_patterns:
            match = re.match(pattern, line)
            if match:
                imports.add(match.group(1))
    
    return imports

def export_to_python(cells: List[Dict]) -> tuple[str, Set[str]]:
    # Convert cells to Cell objects
    cell_objects = [Cell(c["id"], c["code"], c.get("parentId")) for c in cells]
    
    # Create a mapping of cell IDs to their objects for easy lookup
    cell_map = {cell.id: cell for cell in cell_objects}
    
    # Track all imports across all cells
    all_imports = set()
    
    # Helper function to get execution path from root to a cell
    def get_execution_path(cell_id: str) -> List[Cell]:
        path = []
        current_id = cell_id
        while current_id is not None:
            current_cell = cell_map[current_id]
            path.insert(0, current_cell)
            current_id = current_cell.parent_id
        return path

    # Get all leaf cells (cells with no children)
    child_ids = {c.parent_id for c in cell_objects if c.parent_id is not None}
    leaf_cells = [c for c in cell_objects if c.id not in child_ids]
    
    # Get all unique execution paths
    all_paths = []
    for leaf in leaf_cells:
        path = get_execution_path(leaf.id)
        if path not in all_paths:
            all_paths.append(path)
    
    # Generate the Python script
    script_parts = [
        "# Generated by BranchPad\\n",
        "# This script contains all execution paths from the notebook\\n\\n",
        "import sys\\n",
        "from typing import Dict, Any\\n\\n",
        "# Function to execute a cell and maintain its namespace\\n",
        "def execute_cell(code: str, namespace: Dict[str, Any]) -> Dict[str, Any]:\\n",
        "    try:\\n",
        "        exec(code, namespace)\\n",
        "        return namespace\\n",
        "    except Exception as e:\\n",
        "        print(f'Error executing cell: {str(e)}', file=sys.stderr)\\n",
        "        raise\\n\\n",
        "# Function to ensure required packages are installed\\n",
        "def ensure_packages():\\n",
        "    try:\\n",
        "        import micropip\\n",
        "    except ImportError:\\n",
        "        print('micropip not available - skipping package installation')\\n",
        "        return\\n",
        "    \\n",
        "    required_packages = {\\n"
    ]
    
    # Add each execution path as a function
    for i, path in enumerate(all_paths):
        path_name = f"execution_path_{i + 1}"
        path_desc = " -> ".join(c.id for c in path)
        
        script_parts.extend([
            f"def {path_name}():\\n",
            f"    # Execution path: {path_desc}\\n",
            "    namespace = {}\\n"
        ])
        
        # Add each cell's code in the path
        for cell in path:
            # Extract imports from this cell
            imports = extract_imports(cell.code)
            all_imports.update(imports)
            
            # Indent the cell code
            indented_code = textwrap.indent(cell.code.strip(), '        ')
            script_parts.extend([
                f"    # Cell {cell.id}\\n",
                "    try:\\n",
                f"{indented_code}\\n",
                "    except Exception as e:\\n",
                f"        print(f'Error in cell {cell.id}: {{str(e)}}', file=sys.stderr)\\n",
                "        raise\\n\\n"
            ])
        
        script_parts.append("\\n")
    
    # Add the required packages to the ensure_packages function
    for package in sorted(all_imports):
        script_parts.append(f"        '{package}',\\n")
    
    script_parts.extend([
        "    }\\n",
        "    \\n",
        "    for package in required_packages:\\n",
        "        try:\\n",
        "            __import__(package)\\n",
        "        except ImportError:\\n",
        "            print(f'Installing {package}...')\\n",
        "            await micropip.install(package)\\n\\n"
    ])
    
    # Add main section to run all paths
    script_parts.extend([
        "if __name__ == '__main__':\\n",
        "    # Ensure required packages are installed\\n",
        "    ensure_packages()\\n\\n",
        "    # Execute all paths\\n"
    ])
    
    for i in range(len(all_paths)):
        path_name = f"execution_path_{i + 1}"
        script_parts.append(f"    print('\\\\nExecuting {path_name}...')\\n")
        script_parts.append(f"    {path_name}()\\n")
    
    return "".join(script_parts), all_imports

# Export the notebook
result, imports = export_to_python(${JSON.stringify(cellsData)})

# Install any required packages for the current session
try:
    import micropip
    for package in imports:
        try:
            __import__(package)
        except ImportError:
            print(f'Installing {package}...')
            await micropip.install(package)
except ImportError:
    print('micropip not available - skipping package installation')

result  # Return the result to JavaScript
    `);

    // Get the environment information - using sys.modules instead of pkg_resources
    const requirements = await pyodide.runPythonAsync(`
import sys

# Get a list of all imported modules
modules = list(sys.modules.keys())

# Filter out built-in modules and create requirements list
requirements = []
for module in sorted(modules):
    # Skip private modules and built-ins
    if not module.startswith('_') and module not in sys.builtin_module_names:
        try:
            mod = sys.modules[module]
            version = getattr(mod, '__version__', 'latest')
            requirements.append(f"{module}=={version}")
        except:
            pass

"\\n".join(requirements)
    `);

    return {
      pythonScript,
      requirements
    };
  } catch (error) {
    console.error('Error exporting notebook:', error);
    throw error;
  }
}

export function downloadFile(content: string, filename: string) {
  const blob = new Blob([content], { type: 'text/plain' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}

export async function exportAndDownload(pyodide: any, cells: Cell[]) {
  if (!pyodide) return;

  // Create a JSON representation of the notebook
  const notebook = {
    cells: cells.map((cell) => ({
      id: cell.id,
      code: cell.code,
      output: cell.output,
      error: cell.error,
      parentId: cell.parentId,
      label: cell.label,
      description: cell.description,
      color: cell.color,
      snapshots: cell.snapshots,
      currentSnapshotId: cell.currentSnapshotId,
    })),
    metadata: {
      version: "1.0",
      created: new Date().toISOString(),
      pyodideVersion: pyodide.version,
    },
  };

  // Convert to JSON string
  const json = JSON.stringify(notebook, null, 2);

  // Create a blob and download
  const blob = new Blob([json], { type: "application/json" });
  const url = window.URL.createObjectURL(blob);
  const a = document.createElement("a");
  a.href = url;
  a.download = "notebook.json";
  document.body.appendChild(a);
  a.click();
  window.URL.revokeObjectURL(url);
  document.body.removeChild(a);
} 